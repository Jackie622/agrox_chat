{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2bc18420",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "# 读取本地/项目的环境变量。\n",
    "\n",
    "# find_dotenv()寻找并定位.env文件的路径\n",
    "# load_dotenv()读取该.env文件，并将其中的环境变量加载到当前的运行环境中  \n",
    "# 如果你设置的是全局的环境变量，这行代码则没有任何作用。\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "# 获取 DeepSeek API Key\n",
    "deepseek_api_key = os.environ['DEEPSEEK_API_KEY']\n",
    "\n",
    "# 配置 OpenAI 客户端以兼容 DeepSeek API（需确认 DeepSeek 是否兼容 OpenAI 格式）\n",
    "openai.api_key = deepseek_api_key\n",
    "openai.base_url = \"https://api.deepseek.com/v1\"  # 根据 DeepSeek 文档调整"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4f1d1099",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x000001483516D040>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x000001483516E570>, root_client=<openai.OpenAI object at 0x000001483500FFE0>, root_async_client=<openai.AsyncOpenAI object at 0x000001483516D070>, model_name='deepseek-reasoner', temperature=0.0, model_kwargs={}, openai_api_key=SecretStr('**********'), openai_api_base='https://api.deepseek.com/v1')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# 修改后的 DeepSeek 配置\n",
    "llm = ChatOpenAI(\n",
    "    openai_api_key=os.getenv(\"DEEPSEEK_API_KEY\"),  # 从环境变量读取 DeepSeek 的 Key\n",
    "    base_url=\"https://api.deepseek.com/v1\",        # 指向 DeepSeek 的 API 地址\n",
    "    model_name=\"deepseek-reasoner\",                   # 根据 DeepSeek 支持的模型名称修改\n",
    "    temperature=0.0                              # 保持原有参数\n",
    ")\n",
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a84c6946",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = llm.invoke(\"请你创作一篇情诗，写给我异地恋的女友\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "181846d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='《经纬间的潮汐》\\n\\n月光在屏幕上碎成盐粒时\\n我正吞咽着时差酿成的酒\\n你睫毛的倒影卡在像素里\\n像候鸟掠过未校准的纬度线\\n\\n地图折叠处的褶皱藏着我们未拆封的吻\\n每个黄昏都成为两处地址的合谋者\\n潮汐在听筒里涨落\\n我数着心跳校准你窗台的月相\\n\\n十二月的风在键盘上结霜\\n光标闪烁成不眠的灯塔\\n我们用词语搭建透明的桥\\n让呼吸在光纤里长出根系\\n\\n所有未寄达的玫瑰都化作经纬\\n编织着晨昏线交汇的清晨\\n当候鸟再次丈量赤道的弧度\\n我们的影子终将在子午圈上\\n熔成同一枚银币的\\n正反两面', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 475, 'prompt_tokens': 17, 'total_tokens': 492, 'completion_tokens_details': {'accepted_prediction_tokens': None, 'audio_tokens': None, 'reasoning_tokens': 304, 'rejected_prediction_tokens': None}, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}, 'prompt_cache_hit_tokens': 0, 'prompt_cache_miss_tokens': 17}, 'model_name': 'deepseek-reasoner', 'system_fingerprint': 'fp_5417b77867_prod0225', 'finish_reason': 'stop', 'logprobs': None}, id='run-05802bf5-707d-4add-a380-7ac96b283417-0', usage_metadata={'input_tokens': 17, 'output_tokens': 475, 'total_tokens': 492, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 304}})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7e921e14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'请你将由三个反引号分割的文本翻译成英文！text: ```我带着比身体重的行李，游入尼罗河底，经过几道闪电 看到一堆光圈，不确定是不是这里。```\\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# 这里我们要求模型对给定文本进行中文翻译\n",
    "prompt = \"\"\"请你将由三个反引号分割的文本翻译成英文！\\\n",
    "text: ```{text}```\n",
    "\"\"\"\n",
    "\n",
    "text = \"我带着比身体重的行李，\\\n",
    "游入尼罗河底，\\\n",
    "经过几道闪电 看到一堆光圈，\\\n",
    "不确定是不是这里。\\\n",
    "\"\n",
    "prompt.format(text=text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f5d7d4a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='你是一个翻译助手，可以帮助我将 中文 翻译成 英文.', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='我带着比身体重的行李，游入尼罗河底，经过几道闪电 看到一堆光圈，不确定是不是这里。', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts.chat import ChatPromptTemplate\n",
    "\n",
    "template = \"你是一个翻译助手，可以帮助我将 {input_language} 翻译成 {output_language}.\"\n",
    "human_template = \"{text}\"\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", template),\n",
    "    (\"human\", human_template),\n",
    "])\n",
    "\n",
    "text = \"我带着比身体重的行李，\\\n",
    "游入尼罗河底，\\\n",
    "经过几道闪电 看到一堆光圈，\\\n",
    "不确定是不是这里。\\\n",
    "\"\n",
    "messages  = chat_prompt.format_messages(input_language=\"中文\", output_language=\"英文\", text=text)\n",
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8dae7e67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='I carry luggage heavier than my body, diving into the Nile\\'s depths. After passing through lightning strikes, I glimpse clusters of light rings - uncertain if this is where I\\'m meant to be.\\n\\n（翻译说明：保留原诗意境的同时进行适当英语化处理：1. \"游入\"译为\"diving\"更符合潜入深水的语境 2. \"几道闪电\"处理为\"lightning strikes\"增强画面动态感 3. \"光圈\"译为\"light rings\"保持神秘感 4. 末句采用破折号连接和倒装结构，模仿原句的沉吟语气。整体采用现在时态营造身临其境的叙述感。）', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 525, 'prompt_tokens': 47, 'total_tokens': 572, 'completion_tokens_details': {'accepted_prediction_tokens': None, 'audio_tokens': None, 'reasoning_tokens': 383, 'rejected_prediction_tokens': None}, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}, 'prompt_cache_hit_tokens': 0, 'prompt_cache_miss_tokens': 47}, 'model_name': 'deepseek-reasoner', 'system_fingerprint': 'fp_5417b77867_prod0225', 'finish_reason': 'stop', 'logprobs': None}, id='run-92931793-8a31-4a10-a384-c9cc6c6a236c-0', usage_metadata={'input_tokens': 47, 'output_tokens': 525, 'total_tokens': 572, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 383}})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output  = llm.invoke(messages)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b5e5f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-deepseek]",
   "language": "python",
   "name": "conda-env-.conda-deepseek-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
